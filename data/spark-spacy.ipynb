{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workshop Goals\n",
    "\n",
    "### - Get to know Apache Spark engine.\n",
    "\n",
    "### - Understand Spacy NLP library capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apache Spark is a fast and general engine for large-scale data processing\n",
    "![Spark Libs](img/spark-libs.png)\n",
    "\n",
    "### It can access diverse data sources including HDFS, Cassandra, Hive, HBase, S3 and JDBC/ODBC\n",
    "![Spark Compatabilities](img/spark-cmp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hadoop data sharing](img/data-sharing-mapreduce.png)\n",
    "![Spark data sharing](img/data-sharing-spark.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as fun, types\n",
    "\n",
    "import spacy\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark session init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession(SparkContext.getOrCreate()) \\\n",
    "    .builder \\\n",
    "    .appName('NLP') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "News Category Dataset:\n",
    "https://www.kaggle.com/rmisra/news-category-dataset\n",
    "\n",
    "Each json record contains following attributes:\n",
    "\n",
    "* category: Category article belongs to\n",
    "\n",
    "* headline: Headline of the article\n",
    "\n",
    "* authors: Person authored the article\n",
    "\n",
    "* link: Link to the post\n",
    "\n",
    "* short_description: Short description of the article\n",
    "\n",
    "* date: Date the article was published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+----------+--------------------+--------------------+--------------------+\n",
      "|             authors|     category|      date|            headline|                link|   short_description|\n",
      "+--------------------+-------------+----------+--------------------+--------------------+--------------------+\n",
      "|     Melissa Jeltsen|        CRIME|2018-05-26|There Were 2 Mass...|https://www.huffi...|She left her husb...|\n",
      "|       Andy McDonald|ENTERTAINMENT|2018-05-26|Will Smith Joins ...|https://www.huffi...|Of course it has ...|\n",
      "|          Ron Dicker|ENTERTAINMENT|2018-05-26|Hugh Grant Marrie...|https://www.huffi...|The actor and his...|\n",
      "|          Ron Dicker|ENTERTAINMENT|2018-05-26|Jim Carrey Blasts...|https://www.huffi...|The actor gives D...|\n",
      "|          Ron Dicker|ENTERTAINMENT|2018-05-26|Julianna Margulie...|https://www.huffi...|The \"Dietland\" ac...|\n",
      "|          Ron Dicker|ENTERTAINMENT|2018-05-26|Morgan Freeman 'D...|https://www.huffi...|\"It is not right ...|\n",
      "|          Ron Dicker|ENTERTAINMENT|2018-05-26|Donald Trump Is L...|https://www.huffi...|It's catchy, all ...|\n",
      "|     Todd Van Luling|ENTERTAINMENT|2018-05-26|What To Watch On ...|https://www.huffi...|There's a great m...|\n",
      "|       Andy McDonald|ENTERTAINMENT|2018-05-26|Mike Myers Reveal...|https://www.huffi...|Myer's kids may b...|\n",
      "|     Todd Van Luling|ENTERTAINMENT|2018-05-26|What To Watch On ...|https://www.huffi...|You're getting a ...|\n",
      "|   Sebastian Murdock|ENTERTAINMENT|2018-05-26|Justin Timberlake...|https://www.huffi...|The pop star also...|\n",
      "|                    |   WORLD NEWS|2018-05-26|South Korean Pres...|https://www.huffi...|The two met to pa...|\n",
      "|       Karen Pinchin|       IMPACT|2018-05-26|With Its Way Of L...|https://www.huffi...|The revolution is...|\n",
      "|Elise Foley and R...|     POLITICS|2018-05-26|Trump's Crackdown...|https://www.huffi...|Last month a Heal...|\n",
      "|Michael Isikoff, ...|     POLITICS|2018-05-26|'Trump's Son Shou...|https://www.huffi...|The wiretaps feat...|\n",
      "|      Mary Papenfuss|     POLITICS|2018-05-26|Edward Snowden: T...|https://www.huffi...|But don't count o...|\n",
      "|      Mary Papenfuss|     POLITICS|2018-05-26|Booyah: Obama Pho...|https://www.huffi...|Just a peeping mi...|\n",
      "|       Laura Bassett|     POLITICS|2018-05-26|Ireland Votes To ...|https://www.huffi...|Irish women will ...|\n",
      "|      Chris D'Angelo|     POLITICS|2018-05-26|Ryan Zinke Looks ...|https://www.huffi...|The interior secr...|\n",
      "|      Mary Papenfuss|     POLITICS|2018-05-26|Trump's Scottish ...|https://www.huffi...|And there are fou...|\n",
      "+--------------------+-------------+----------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "news_df = spark.read.json(\"News_Category_Dataset_v2.json\")\n",
    "news_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.createOrReplaceTempView(\"news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "| count|\n",
      "+------+\n",
      "|200853|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT(*) AS count FROM news\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200853"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|      category|count|\n",
      "+--------------+-----+\n",
      "|      POLITICS|32739|\n",
      "|      WELLNESS|17827|\n",
      "| ENTERTAINMENT|16058|\n",
      "|        TRAVEL| 9887|\n",
      "|STYLE & BEAUTY| 9649|\n",
      "|     PARENTING| 8677|\n",
      "|HEALTHY LIVING| 6694|\n",
      "|  QUEER VOICES| 6314|\n",
      "|  FOOD & DRINK| 6226|\n",
      "|      BUSINESS| 5937|\n",
      "|        COMEDY| 5175|\n",
      "|        SPORTS| 4884|\n",
      "|  BLACK VOICES| 4528|\n",
      "| HOME & LIVING| 4195|\n",
      "|       PARENTS| 3955|\n",
      "| THE WORLDPOST| 3664|\n",
      "|      WEDDINGS| 3651|\n",
      "|         WOMEN| 3490|\n",
      "|        IMPACT| 3459|\n",
      "|       DIVORCE| 3426|\n",
      "+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT category, count(category) AS count FROM news GROUP BY category ORDER BY count DESC\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|      category|count|\n",
      "+--------------+-----+\n",
      "|      POLITICS|32739|\n",
      "|      WELLNESS|17827|\n",
      "| ENTERTAINMENT|16058|\n",
      "|        TRAVEL| 9887|\n",
      "|STYLE & BEAUTY| 9649|\n",
      "|     PARENTING| 8677|\n",
      "|HEALTHY LIVING| 6694|\n",
      "|  QUEER VOICES| 6314|\n",
      "|  FOOD & DRINK| 6226|\n",
      "|      BUSINESS| 5937|\n",
      "|        COMEDY| 5175|\n",
      "|        SPORTS| 4884|\n",
      "|  BLACK VOICES| 4528|\n",
      "| HOME & LIVING| 4195|\n",
      "|       PARENTS| 3955|\n",
      "| THE WORLDPOST| 3664|\n",
      "|      WEDDINGS| 3651|\n",
      "|         WOMEN| 3490|\n",
      "|        IMPACT| 3459|\n",
      "|       DIVORCE| 3426|\n",
      "+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "news_df.groupby('category') \\\n",
    "    .count() \\\n",
    "    .orderBy(fun.desc('count')) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1. Select the longest headline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Use `length` function and `LIMIT` expression in SQL\n",
    "\n",
    "Available functions: http://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#module-pyspark.sql.functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|            headline|max_headline|\n",
      "+--------------------+------------+\n",
      "|Wendy Williams An...|         320|\n",
      "+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT headline, length(headline) AS max_headline FROM news ORDER BY max_headline DESC limit 1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy NLP library\n",
    "![Spacy Features](img/spacy-features.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy pipeline\n",
    "![Spacy Features](img/spacy-pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In\n",
      "2018\n",
      "the\n",
      "Debian\n",
      "Linux\n",
      "project\n",
      "received\n",
      "a\n",
      "donation\n",
      "of\n",
      "$\n",
      "300,000\n"
     ]
    }
   ],
   "source": [
    "# import spacy \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"In 2018 the Debian Linux project received a donation of $300,000\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the Debian Linux project\n",
      "a donation\n"
     ]
    }
   ],
   "source": [
    "for token in doc.noun_chunks:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n",
      "300,000\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    if token.like_num:\n",
    "        print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2. Extract named entities from the string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Use `ents` attribute of the `Doc` and `label_` attribute of the `Token`\n",
    "\n",
    "Spacy Cheat Sheet: http://datacamp-community-prod.s3.amazonaws.com/29aa28bf-570a-4965-8f54-d6a541ae4e06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n",
      "Debian\n",
      "Linux\n",
      "300,000\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's combine a power of these two instruments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3. Extract ORG, PERSON, GPE named entities in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Write a function that takes a news headline and generate the output like that\n",
    "\n",
    "[\n",
    "  {\n",
    "    'label': 'ORG', \n",
    "    'text': 'ACME Inc.'\n",
    "  },\n",
    "  {\n",
    "    'label': 'PERSON', \n",
    "    'text': 'John Doe'   \n",
    "  },\n",
    "  {\n",
    "    'label': GPE,\n",
    "    'text': 'London'\n",
    "  }\n",
    "  ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df_sample = news_df.sample(withReplacement=False, fraction=0.002, seed=777)\n",
    "news_df_sample.createOrReplaceTempView(\"news_sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpacyWrapper(object):\n",
    "    \"\"\"Wrapper class to load Spacy on worker nodes\"\"\"\n",
    "    _spacys = {}\n",
    "    disabled_pipeline_steps = ['parser', 'tagger']\n",
    "    default_model = 'en_core_web_sm'\n",
    "\n",
    "    @classmethod\n",
    "    def get(cls, model=default_model, disable=disabled_pipeline_steps):\n",
    "        if model not in cls._spacys:\n",
    "            import spacy\n",
    "            cls._spacys[model] = spacy.load(model, disable=disable)\n",
    "        return cls._spacys[model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neamed entity extraction function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Reuse the code from `Task 2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner(doc):\n",
    "    labels=['ORG', 'PERSON', 'GPE']\n",
    "    entities = []\n",
    "    \n",
    "    # Load Spacy\n",
    "    nlp = SpacyWrapper.get()\n",
    "    doc = nlp(doc)\n",
    "    for ent in doc.ents:\n",
    "        entity = {\n",
    "            'label' : ent.label_,\n",
    "            'text' : ent.text\n",
    "        }\n",
    "        entities.append(entity)\n",
    "        \n",
    "    # ======== WRITE YOUR SOLUTION BELOW ======== \n",
    "        \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.ner(doc)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Schema definition\n",
    "schema = types.ArrayType(\n",
    "    types.StructType([\n",
    "        types.StructField('label', types.StringType(), nullable=False),\n",
    "        types.StructField('text', types.StringType(), nullable=False)\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Register user defined function (UDF) to use in SQL\n",
    "spark.udf.register('ner', ner, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply UDF to extract headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_sample = spark.sql(\"SELECT * FROM news_sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ent_sample.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kevin Robillard</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>2018-05-21</td>\n",
       "      <td>Super PACs That Meddled In West Virginia’s Senate Primary Didn’t Receive A P...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/super-pacs-that-meddled-in-west-virgini...</td>\n",
       "      <td>The outside groups can spend big to alter election outcomes, but don't have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sara Boboltz</td>\n",
       "      <td>WORLD NEWS</td>\n",
       "      <td>2018-05-12</td>\n",
       "      <td>Knife Attack In Paris Leaves 1 Dead, Several Injured</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/knife-attack-paris-dead-injured_us_5af7...</td>\n",
       "      <td>The Islamic State claimed responsibility.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Doha Madani</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>White House Knew About Rob Porter Allegations A Year Ago: FBI Letter</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/fbi-congress-letter-rob-porter-white-ho...</td>\n",
       "      <td>The letter to Congress contradicts the White House's account of the spousal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arthur Delaney</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>Republicans Say People Would Kick Themselves Off Food Stamps Under Their New...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/republicans-food-stamps_us_5ad76c97e4b0...</td>\n",
       "      <td>Like self-deportation, but for basic nutritional needs!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dominique Mosbergen</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>2018-03-29</td>\n",
       "      <td>NRA Is Pulling In Big Bucks After The Parkland Mass Shooting</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/nra-donations-parkland-shooting_us_5abc...</td>\n",
       "      <td>Donations skyrocketed as the gun group issued frothy warnings of the \"freedo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               authors    category        date  \\\n",
       "0      Kevin Robillard    POLITICS  2018-05-21   \n",
       "1         Sara Boboltz  WORLD NEWS  2018-05-12   \n",
       "2          Doha Madani    POLITICS  2018-04-27   \n",
       "3       Arthur Delaney    POLITICS  2018-04-18   \n",
       "4  Dominique Mosbergen    POLITICS  2018-03-29   \n",
       "\n",
       "                                                                          headline  \\\n",
       "0  Super PACs That Meddled In West Virginia’s Senate Primary Didn’t Receive A P...   \n",
       "1                             Knife Attack In Paris Leaves 1 Dead, Several Injured   \n",
       "2             White House Knew About Rob Porter Allegations A Year Ago: FBI Letter   \n",
       "3  Republicans Say People Would Kick Themselves Off Food Stamps Under Their New...   \n",
       "4                     NRA Is Pulling In Big Bucks After The Parkland Mass Shooting   \n",
       "\n",
       "                                                                              link  \\\n",
       "0  https://www.huffingtonpost.com/entry/super-pacs-that-meddled-in-west-virgini...   \n",
       "1  https://www.huffingtonpost.com/entry/knife-attack-paris-dead-injured_us_5af7...   \n",
       "2  https://www.huffingtonpost.com/entry/fbi-congress-letter-rob-porter-white-ho...   \n",
       "3  https://www.huffingtonpost.com/entry/republicans-food-stamps_us_5ad76c97e4b0...   \n",
       "4  https://www.huffingtonpost.com/entry/nra-donations-parkland-shooting_us_5abc...   \n",
       "\n",
       "                                                                 short_description  \n",
       "0  The outside groups can spend big to alter election outcomes, but don't have ...  \n",
       "1                                        The Islamic State claimed responsibility.  \n",
       "2  The letter to Congress contradicts the White House's account of the spousal ...  \n",
       "3                          Like self-deportation, but for basic nutritional needs!  \n",
       "4  Donations skyrocketed as the gun group issued frothy warnings of the \"freedo...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>The outside groups can spend big to alter election outcomes, but don't have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WORLD NEWS</td>\n",
       "      <td>The Islamic State claimed responsibility.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>The letter to Congress contradicts the White House's account of the spousal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>Like self-deportation, but for basic nutritional needs!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>Donations skyrocketed as the gun group issued frothy warnings of the \"freedo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     category  \\\n",
       "0    POLITICS   \n",
       "1  WORLD NEWS   \n",
       "2    POLITICS   \n",
       "3    POLITICS   \n",
       "4    POLITICS   \n",
       "\n",
       "                                                                 short_description  \n",
       "0  The outside groups can spend big to alter election outcomes, but don't have ...  \n",
       "1                                        The Islamic State claimed responsibility.  \n",
       "2  The letter to Congress contradicts the White House's account of the spousal ...  \n",
       "3                          Like self-deportation, but for basic nutritional needs!  \n",
       "4  Donations skyrocketed as the gun group issued frothy warnings of the \"freedo...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[['category', 'short_description']]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save output to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT short_description, ner(short_description) AS entities FROM news_sample\") \\\n",
    "    .repartition(1) \\\n",
    "    .write \\\n",
    "    .json(\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n",
      "['POLITICS' 'WORLD NEWS' 'ENTERTAINMENT' 'WOMEN' 'BLACK VOICES' 'GREEN'\n",
      " 'SPORTS' 'WEIRD NEWS' 'QUEER VOICES' 'TASTE' 'COMEDY' 'EDUCATION' 'STYLE'\n",
      " 'PARENTS' 'SCIENCE' 'HEALTHY LIVING' 'TRAVEL' 'THE WORLDPOST' 'MEDIA'\n",
      " 'BUSINESS' 'RELIGION' 'LATINO VOICES' 'CRIME' 'TECH' 'ARTS'\n",
      " 'ARTS & CULTURE' 'GOOD NEWS' 'WORLDPOST' 'IMPACT' 'FIFTY' 'COLLEGE'\n",
      " 'PARENTING' 'STYLE & BEAUTY' 'WEDDINGS' 'MONEY' 'WELLNESS' 'FOOD & DRINK'\n",
      " 'HOME & LIVING' 'CULTURE & ARTS' 'DIVORCE']\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "print(\"Created blank 'en' model\")\n",
    "categories = dataset.category.unique()\n",
    "print(categories)\n",
    "textcat = nlp.create_pipe(\n",
    "            \"textcat\",\n",
    "            config={\n",
    "                \"exclusive_classes\": True,\n",
    "                \"architecture\": \"simple_cnn\",\n",
    "            }\n",
    "        )\n",
    "nlp.add_pipe(textcat, last=True)\n",
    "for singleCat in categories:\n",
    "    textcat.add_label(\"NEGATIVE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"textcat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.util import minibatch, compounding\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>The outside groups can spend big to alter election outcomes, but don't have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WORLD NEWS</td>\n",
       "      <td>The Islamic State claimed responsibility.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>The letter to Congress contradicts the White House's account of the spousal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>Like self-deportation, but for basic nutritional needs!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>Donations skyrocketed as the gun group issued frothy warnings of the \"freedo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     category  \\\n",
       "0    POLITICS   \n",
       "1  WORLD NEWS   \n",
       "2    POLITICS   \n",
       "3    POLITICS   \n",
       "4    POLITICS   \n",
       "\n",
       "                                                                 short_description  \n",
       "0  The outside groups can spend big to alter election outcomes, but don't have ...  \n",
       "1                                        The Islamic State claimed responsibility.  \n",
       "2  The letter to Congress contradicts the White House's account of the spousal ...  \n",
       "3                          Like self-deportation, but for basic nutritional needs!  \n",
       "4  Donations skyrocketed as the gun group issued frothy warnings of the \"freedo...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_c = list(trainSet.category)\n",
    "train_tex = list(trainSet.short_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Islamic State claimed responsibility.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tex[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POLITICS', 'WORLD NEWS', 'ENTERTAINMENT', 'WOMEN', 'BLACK VOICES',\n",
       "       'GREEN', 'SPORTS', 'WEIRD NEWS', 'QUEER VOICES', 'TASTE', 'COMEDY',\n",
       "       'EDUCATION', 'STYLE', 'PARENTS', 'SCIENCE', 'HEALTHY LIVING',\n",
       "       'TRAVEL', 'THE WORLDPOST', 'MEDIA', 'BUSINESS', 'RELIGION',\n",
       "       'LATINO VOICES', 'CRIME', 'TECH', 'ARTS', 'ARTS & CULTURE',\n",
       "       'GOOD NEWS', 'WORLDPOST', 'IMPACT', 'FIFTY', 'COLLEGE',\n",
       "       'PARENTING', 'STYLE & BEAUTY', 'WEDDINGS', 'MONEY', 'WELLNESS',\n",
       "       'FOOD & DRINK', 'HOME & LIVING', 'CULTURE & ARTS', 'DIVORCE'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSet.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WORLD NEWS'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_c[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_to_dict(target):\n",
    "    tarDict = dict()\n",
    "    for cat in trainSet.category.unique():\n",
    "        tarDict[cat] = target == cat\n",
    "    return tarDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet['target'] = trainSet['category'].apply(encode_to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_c = list(trainSet.target)\n",
    "train_tex = list(trainSet.short_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The Islamic State claimed responsibility.', {'cats': {'POLITICS': False, 'WORLD NEWS': True, 'ENTERTAINMENT': False, 'WOMEN': False, 'BLACK VOICES': False, 'GREEN': False, 'SPORTS': False, 'WEIRD NEWS': False, 'QUEER VOICES': False, 'TASTE': False, 'COMEDY': False, 'EDUCATION': False, 'STYLE': False, 'PARENTS': False, 'SCIENCE': False, 'HEALTHY LIVING': False, 'TRAVEL': False, 'THE WORLDPOST': False, 'MEDIA': False, 'BUSINESS': False, 'RELIGION': False, 'LATINO VOICES': False, 'CRIME': False, 'TECH': False, 'ARTS': False, 'ARTS & CULTURE': False, 'GOOD NEWS': False, 'WORLDPOST': False, 'IMPACT': False, 'FIFTY': False, 'COLLEGE': False, 'PARENTING': False, 'STYLE & BEAUTY': False, 'WEDDINGS': False, 'MONEY': False, 'WELLNESS': False, 'FOOD & DRINK': False, 'HOME & LIVING': False, 'CULTURE & ARTS': False, 'DIVORCE': False}})\n"
     ]
    }
   ],
   "source": [
    "train_data = list(zip(train_tex, [{\"cats\": cats} for cats in train_c]))\n",
    "print(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unnamed vectors -- this won't allow multiple vectors models to be loaded. (Shape: (0, 0))\n"
     ]
    }
   ],
   "source": [
    "with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "    optimizer = nlp.begin_training()\n",
    "    batch_sizes = compounding(4.0, 32.0, 1.001)\n",
    "    for i in range(n_iter):\n",
    "        losses = {}\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        random.shuffle(train_data)\n",
    "        batches = minibatch(train_data, size=batch_sizes)\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, annotations, sgd=optimizer, drop=0.2, losses=losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
